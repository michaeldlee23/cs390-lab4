{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGsz7PXkd/iD2E0M7DR30e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaeldlee23/cs390-lab4/blob/master/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F-WiwbhpcEQ",
        "outputId": "44fb88e9-cf40-430e-9d2e-e073d40082a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuAIXJieoyVP"
      },
      "source": [
        "# CS390-NIP GAN lab\n",
        "# Max Jacobson / Sri Cherukuri / Anthony Niemiec\n",
        "# FA2020\n",
        "# uses Fashion MNIST https://www.kaggle.com/zalando-research/fashionmnist \n",
        "# uses CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import imageio\n",
        "import shutil"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pashueYgo2jC"
      },
      "source": [
        "random.seed(1618)\n",
        "np.random.seed(1618)\n",
        "tf.compat.v1.set_random_seed(1618)\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "DRIVE_PREFIX = '/content/drive/My Drive/Colab Notebooks/lab4/'\n",
        "\n",
        "# NOTE: mnist_d is no credit\n",
        "# NOTE: cifar_10 is extra credit\n",
        "# DATASET = \"mnist_d\"\n",
        "DATASET = \"mnist_f\"\n",
        "# DATASET = \"cifar_10\"\n",
        "\n",
        "if DATASET == \"mnist_d\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    LABEL = \"numbers\"\n",
        "elif DATASET == \"mnist_f\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    CLASSLIST = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        "    # TODO: choose a label to train on from the CLASSLIST above\n",
        "    LABEL = \"dress\"\n",
        "elif DATASET == \"cifar_10\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (32, 32, 3)\n",
        "    CLASSLIST = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "    LABEL = \"dog\"\n",
        "\n",
        "IMAGE_SIZE = IH*IW*IZ\n",
        "\n",
        "NOISE_SIZE = 100    # length of noise array\n",
        "\n",
        "TRAIN_RATIO = 1     # Number of generator updates per discriminator update\n",
        "\n",
        "# file prefixes and directory\n",
        "OUTPUT_NAME = DATASET + \"_\" + LABEL\n",
        "OUTPUT_DIR = DRIVE_PREFIX + \"./outputs/\" + OUTPUT_NAME\n",
        "\n",
        "# Tensorbord directories\n",
        "ADV_LOG_DIR = DRIVE_PREFIX + './logs/' + OUTPUT_NAME + '/advLoss'\n",
        "GEN_LOG_DIR = DRIVE_PREFIX + './logs/' + OUTPUT_NAME + '/genLoss'\n",
        "\n",
        "# NOTE: switch to True in order to receive debug information\n",
        "VERBOSE_OUTPUT = False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVuKnuWuaKrD"
      },
      "source": [
        "################################### HELPER FUNCTIONS ###################################\n",
        "def namedLogs(model, logs):\n",
        "    result = dict()\n",
        "    for l in zip(model.metrics_names, logs):\n",
        "        result[l[0]] = l[1]\n",
        "    return result\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Knbe7rFo5kK"
      },
      "source": [
        "################################### DATA FUNCTIONS ###################################\n",
        "\n",
        "# Load in and report the shape of dataset\n",
        "def getRawData():\n",
        "    if DATASET == \"mnist_f\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    elif DATASET == \"cifar_10\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.cifar10.load_data()\n",
        "    elif DATASET == \"mnist_d\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.mnist.load_data()\n",
        "    print(\"Shape of xTrain dataset: %s.\" % str(xTrain.shape))\n",
        "    print(\"Shape of yTrain dataset: %s.\" % str(yTrain.shape))\n",
        "    print(\"Shape of xTest dataset: %s.\" % str(xTest.shape))\n",
        "    print(\"Shape of yTest dataset: %s.\" % str(yTest.shape))\n",
        "    return ((xTrain, yTrain), (xTest, yTest))\n",
        "\n",
        "# Filter out the dataset to only include images with our LABEL, meaning we may also discard\n",
        "# class labels for the images because we know exactly what to expect\n",
        "def preprocessData(raw):\n",
        "    ((xTrain, yTrain), (xTest, yTest)) = raw\n",
        "    if DATASET == \"mnist_d\":\n",
        "        xP = np.r_[xTrain, xTest]\n",
        "    else:\n",
        "        c = CLASSLIST.index(LABEL)\n",
        "        x = np.r_[xTrain, xTest]\n",
        "        y = np.r_[yTrain, yTest].flatten()\n",
        "        ilist = [i for i in range(y.shape[0]) if y[i] == c]\n",
        "        xP = x[ilist]\n",
        "    # NOTE: Normalize from 0 to 1 or -1 to 1\n",
        "    #xP = xP/255.0\n",
        "    xP = xP/127.5 - 1\n",
        "    print(\"Shape of Preprocessed dataset: %s.\" % str(xP.shape))\n",
        "    return xP"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmrX6Or_pxvf"
      },
      "source": [
        "################################# BUILDING NETWORKS ##################################\n",
        "#################################      MNIST_F      ##################################\n",
        "\n",
        "# Model that discriminates between fake and real dataset images\n",
        "def buildDiscriminator(dropRate=0.2):\n",
        "    # Calculating output size for Conv2D\n",
        "    # When padding = same:\n",
        "    #   H = H1 / stride\n",
        "    # When padding = valid:\n",
        "    #   H = (H1 - HF + 1) / stride\n",
        "    # Where H = output height (resp, width), H1 = input height, HF = filter height\n",
        "    model = Sequential(name=\"MNIST_DISCRIMINATOR\")\n",
        "\n",
        "    # output shape: (14, 14, 64)\n",
        "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    # output shape: (7, 7, 128)\n",
        "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(2 * dropRate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a discriminator which takes in a (28 x 28 x 1) image - possibly from mnist_f\n",
        "    #       and possibly from the generator - and outputs a single digit REAL (1) or FAKE (0)\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = IMAGE_SHAPE)\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "# Model that generates a fake image from random noise\n",
        "def buildGenerator():\n",
        "    # from https://datascience.stackexchange.com/questions/26451/how-to-calculate-the-output-shape-of-conv2d-transpose\n",
        "    # Calculating output size for Conv2DTranspose\n",
        "    # When padding = same:\n",
        "    #   H = H1 * stride\n",
        "    # When padding = valid:\n",
        "    #   H = (H1-1) * stride + HF\n",
        "    # Where H = output height (resp, width), H1 = input height, HF = filter height\n",
        "    kernelSize = (5, 5)\n",
        "    model = Sequential(name=\"MNIST_GENERATOR\")\n",
        "\n",
        "    model.add(Dense(7 * 7 * 128, input_dim = NOISE_SIZE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "\n",
        "    # Output shape: (14, 14, 64)\n",
        "    model.add(Conv2DTranspose(64, kernelSize, strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Output shape: (28, 28, 1)\n",
        "    model.add(Conv2DTranspose(IZ, kernelSize, strides=(2, 2), padding='same', activation='tanh')) \n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a generator which takes in a (NOISE_SIZE) noise array and outputs a fake\n",
        "    #       mnist_f (28 x 28 x 1) image\n",
        "    assert model.output_shape == (None, IH, IW, IZ)\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = (NOISE_SIZE,))\n",
        "    return Model(inputTensor, model(inputTensor))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQgvQcuo9jG"
      },
      "source": [
        "################################# BUILDING NETWORKS ##################################\n",
        "#################################     CIFAR_10      ##################################\n",
        "\n",
        "# Model that discriminates between fake and real dataset images\n",
        "def buildDiscriminator(dropRate=0.2):\n",
        "    model = Sequential(name=\"CIFAR_DISCRIMINATOR\")\n",
        "    kernelSize = (3, 3)\n",
        "    alpha = 0.2\n",
        "    momentum = 0.8\n",
        "\n",
        "    # output size will be (16, 16, 32)\n",
        "    model.add(Conv2D(32, kernelSize, strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be (8, 8, 64)\n",
        "    model.add(Conv2D(64, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be (4, 4, 128)\n",
        "    model.add(Conv2D(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be (2, 2, 256)\n",
        "    # model.add(Conv2D(256, kernelSize, strides=(2, 2), padding='same'))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    # model.add(LeakyReLU(alpha))\n",
        "    # model.add(Dropout(dropRate))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    # model.add(Dense(1024))\n",
        "    # model.add(LeakyReLU(alpha))\n",
        "    # model.add(Dropout(2 * dropRate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a discriminator which takes in a (28 x 28 x 1) image - possibly from mnist_f\n",
        "    #       and possibly from the generator - and outputs a single digit REAL (1) or FAKE (0)\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = IMAGE_SHAPE)\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "# Model that generates a fake image from random noise\n",
        "def buildGenerator():\n",
        "    kernelSize = (3, 3)\n",
        "    alpha = 0.2\n",
        "    momentum = 0.8\n",
        "    model = Sequential(name=\"CIFAR_GENERATOR\")\n",
        "\n",
        "    model.add(Dense(7 * 7 * 256, input_dim = NOISE_SIZE))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum))\n",
        "    \n",
        "    # output shape is (4, 4, 256)\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "\n",
        "    # output size will be (8, 8, 256)\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernelSize, padding='same', activation='relu'))\n",
        "    # model.add(Conv2DTranspose(256, kernelSize, strides=(2, 2), padding='same'))\n",
        "    # model.add(LeakyReLU(alpha))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "\n",
        "    # output size will be (16, 16, 256)\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256, kernelSize, padding='same', activation='relu'))\n",
        "    # model.add(Conv2DTranspose(256, kernelSize, strides=(2, 2), padding='same'))\n",
        "    # model.add(LeakyReLU(alpha))\n",
        "    model.add(BatchNormalization(momentum=momentum))\n",
        "\n",
        "    # output size will be (32, 32, 128)\n",
        "    # model.add(UpSampling2D())\n",
        "    # model.add(Conv2D(128, kernelSize, padding='same', activation='relu'))\n",
        "    # # model.add(Conv2DTranspose(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    # # model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # output size will be (32, 32, 3)\n",
        "    model.add(Conv2D(IZ, kernelSize, padding='same', activation='tanh')) \n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a generator which takes in a (NOISE_SIZE) noise array and outputs a fake\n",
        "    #       mnist_f (28 x 28 x 1) image\n",
        "    assert model.output_shape == (None, IH, IW, IZ)\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = (NOISE_SIZE,))\n",
        "    return Model(inputTensor, model(inputTensor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFt6Urs0I9T"
      },
      "source": [
        "################################### CREATING A GAN ###################################\n",
        "\n",
        "def buildGAN(images, epochs = 40000, batchSize = 32, loggingInterval = 0):\n",
        "    # Setup\n",
        "    opt = Adam(0.0002, 0.5)\n",
        "    loss = \"binary_crossentropy\"\n",
        "\n",
        "    # Setup adversary\n",
        "    adversary = buildDiscriminator()\n",
        "    adversary.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "    # Setup generator and GAN\n",
        "    adversary.trainable = False                     # freeze adversary's weights when training GAN\n",
        "    generator = buildGenerator()                    # generator is trained within GAN in relation to adversary performance\n",
        "    noise = Input(shape = (NOISE_SIZE,))\n",
        "    gan = Model(noise, adversary(generator(noise))) # GAN feeds generator into adversary\n",
        "    gan.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "    # Tensorboard logging setup\n",
        "    advTensorboard = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=ADV_LOG_DIR,\n",
        "    )\n",
        "    advTensorboard.set_model(adversary)\n",
        "\n",
        "    genTensorboard = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=GEN_LOG_DIR,\n",
        "    )\n",
        "    genTensorboard.set_model(gan)\n",
        "\n",
        "    # Training\n",
        "    trueCol = np.ones((batchSize, 1))\n",
        "    falseCol = np.zeros((batchSize, 1))\n",
        "    start = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator with a true and false batch\n",
        "        batch = images[np.random.randint(0, images.shape[0], batchSize)]\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genImages = generator.predict(noise)\n",
        "        if epoch % TRAIN_RATIO == 0:\n",
        "            advTrueLoss = adversary.train_on_batch(batch, trueCol)\n",
        "            advFalseLoss = adversary.train_on_batch(genImages, falseCol)\n",
        "            advLoss = np.add(advTrueLoss, advFalseLoss) * 0.5\n",
        "\n",
        "        # Train generator by training GAN while keeping adversary component constant\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genLoss = gan.train_on_batch(noise, trueCol)\n",
        "\n",
        "        # Logging\n",
        "        if loggingInterval > 0 and epoch % loggingInterval == 0 or epoch == epochs - 1:\n",
        "            end = time.time()\n",
        "            print(\"\\tEpoch %d:\" % epoch)\n",
        "            print(\"\\t\\tDiscriminator loss: %f.\" % advLoss[0])\n",
        "            print(\"\\t\\tDiscriminator accuracy: %.2f%%.\" % (100 * advLoss[1]))\n",
        "            print(\"\\t\\tGenerator loss: %f.\" % genLoss[0])\n",
        "            print(\"\\t\\tCompleted in %ds\" % (end - start))\n",
        "            start = time.time()\n",
        "            # Tensorboard logging\n",
        "            runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_test_%d.png\" % (epoch / loggingInterval))\n",
        "            advTensorboard.on_epoch_end(epoch, namedLogs(adversary, [advLoss[0]]))\n",
        "            genTensorboard.on_epoch_end(epoch, namedLogs(gan, [genLoss[0]]))\n",
        "    advTensorboard.on_train_end(None)\n",
        "    genTensorboard.on_train_end(None)\n",
        "    return (generator, adversary, gan)\n",
        "\n",
        "# Generates an image using given generator\n",
        "def runGAN(generator, outfile):\n",
        "    noise = np.random.normal(0, 1, (1, NOISE_SIZE)) # generate a random noise array\n",
        "    img = generator.predict(noise)[0]               # run generator on noise\n",
        "    img = np.squeeze(img)                           # readjust image shape if needed\n",
        "    img = (0.5*img + 0.5)*255                       # adjust values to range from 0 to 255 as needed\n",
        "    imageio.imwrite(outfile, img.astype('uint8'))   # store resulting image\n",
        "    print('\\t\\tSaved image to %s' % outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5qhTdQLoVHq",
        "outputId": "962ac9b0-4a80-4ae3-dfa2-3cc71ea5c151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "################################### RUNNING THE PIPELINE #############################\n",
        "\n",
        "def main():\n",
        "    print(\"Starting %s image generator program.\" % LABEL)\n",
        "    if os.path.exists(OUTPUT_DIR):\n",
        "        print('Removing old outputs...')\n",
        "        shutil.rmtree(OUTPUT_DIR)   # remove old outputs\n",
        "    if os.path.exists(ADV_LOG_DIR):\n",
        "        print('Removing old adversary logs...')\n",
        "        shutil.rmtree(ADV_LOG_DIR)  # remove old adversary logs\n",
        "    if os.path.exists(GEN_LOG_DIR):\n",
        "        print('Removing old generator logs...')\n",
        "        shutil.rmtree(GEN_LOG_DIR)  # remove old generator logs\n",
        "    print('Making new output directory...')\n",
        "    os.makedirs(OUTPUT_DIR)         # make new output directory\n",
        "    print('Making new adversary logs directory...')\n",
        "    os.makedirs(ADV_LOG_DIR)        # make new adversary logs\n",
        "    print('Making new generator logs directory...')\n",
        "    os.makedirs(GEN_LOG_DIR)        # make new generator logs\n",
        "    # Receive all of mnist_f\n",
        "    raw = getRawData()\n",
        "    # Filter for just the class we are trying to generate\n",
        "    data = preprocessData(raw)\n",
        "    # Create and train all facets of the GAN\n",
        "    (generator, adv, gan) = buildGAN(data, epochs = 10000, loggingInterval = 500)\n",
        "    # Utilize our spooky neural net gimmicks to create realistic counterfeit images\n",
        "    for i in range(10):\n",
        "        runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_final_%d.png\" % i)\n",
        "    print(\"Images saved in %s directory.\" % OUTPUT_DIR)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting dress image generator program.\n",
            "Removing old outputs...\n",
            "Removing old adversary logs...\n",
            "Removing old generator logs...\n",
            "Making new output directory...\n",
            "Making new adversary logs directory...\n",
            "Making new generator logs directory...\n",
            "Shape of xTrain dataset: (60000, 28, 28).\n",
            "Shape of yTrain dataset: (60000,).\n",
            "Shape of xTest dataset: (10000, 28, 28).\n",
            "Shape of yTest dataset: (10000,).\n",
            "Shape of Preprocessed dataset: (7000, 28, 28).\n",
            "Model: \"MNIST_DISCRIMINATOR\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 6,500,097\n",
            "Trainable params: 6,500,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"MNIST_GENERATOR\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)   (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6272)              25088     \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 14, 14, 64)        204864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 28, 28, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 865,281\n",
            "Trainable params: 852,609\n",
            "Non-trainable params: 12,672\n",
            "_________________________________________________________________\n",
            "\tEpoch 0:\n",
            "\t\tDiscriminator loss: 0.679805.\n",
            "\t\tDiscriminator accuracy: 40.62%.\n",
            "\t\tGenerator loss: 0.481515.\n",
            "\t\tCompleted in 1s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_0.png\n",
            "\tEpoch 500:\n",
            "\t\tDiscriminator loss: 0.674347.\n",
            "\t\tDiscriminator accuracy: 70.31%.\n",
            "\t\tGenerator loss: 1.889421.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_1.png\n",
            "\tEpoch 1000:\n",
            "\t\tDiscriminator loss: 0.630543.\n",
            "\t\tDiscriminator accuracy: 68.75%.\n",
            "\t\tGenerator loss: 0.988775.\n",
            "\t\tCompleted in 26s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_2.png\n",
            "\tEpoch 1500:\n",
            "\t\tDiscriminator loss: 0.554902.\n",
            "\t\tDiscriminator accuracy: 68.75%.\n",
            "\t\tGenerator loss: 1.236202.\n",
            "\t\tCompleted in 26s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_3.png\n",
            "\tEpoch 2000:\n",
            "\t\tDiscriminator loss: 0.378807.\n",
            "\t\tDiscriminator accuracy: 85.94%.\n",
            "\t\tGenerator loss: 1.519695.\n",
            "\t\tCompleted in 26s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_4.png\n",
            "\tEpoch 2500:\n",
            "\t\tDiscriminator loss: 0.510059.\n",
            "\t\tDiscriminator accuracy: 70.31%.\n",
            "\t\tGenerator loss: 1.330997.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_5.png\n",
            "\tEpoch 3000:\n",
            "\t\tDiscriminator loss: 0.678304.\n",
            "\t\tDiscriminator accuracy: 60.94%.\n",
            "\t\tGenerator loss: 1.184983.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_6.png\n",
            "\tEpoch 3500:\n",
            "\t\tDiscriminator loss: 0.596949.\n",
            "\t\tDiscriminator accuracy: 70.31%.\n",
            "\t\tGenerator loss: 1.141699.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_7.png\n",
            "\tEpoch 4000:\n",
            "\t\tDiscriminator loss: 0.574730.\n",
            "\t\tDiscriminator accuracy: 62.50%.\n",
            "\t\tGenerator loss: 1.130176.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_8.png\n",
            "\tEpoch 4500:\n",
            "\t\tDiscriminator loss: 0.704852.\n",
            "\t\tDiscriminator accuracy: 57.81%.\n",
            "\t\tGenerator loss: 1.431814.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_9.png\n",
            "\tEpoch 5000:\n",
            "\t\tDiscriminator loss: 0.539101.\n",
            "\t\tDiscriminator accuracy: 73.44%.\n",
            "\t\tGenerator loss: 1.442764.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_10.png\n",
            "\tEpoch 5500:\n",
            "\t\tDiscriminator loss: 0.584584.\n",
            "\t\tDiscriminator accuracy: 70.31%.\n",
            "\t\tGenerator loss: 1.215287.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_11.png\n",
            "\tEpoch 6000:\n",
            "\t\tDiscriminator loss: 0.652524.\n",
            "\t\tDiscriminator accuracy: 60.94%.\n",
            "\t\tGenerator loss: 1.255739.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_12.png\n",
            "\tEpoch 6500:\n",
            "\t\tDiscriminator loss: 0.624730.\n",
            "\t\tDiscriminator accuracy: 64.06%.\n",
            "\t\tGenerator loss: 1.220862.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_13.png\n",
            "\tEpoch 7000:\n",
            "\t\tDiscriminator loss: 0.642722.\n",
            "\t\tDiscriminator accuracy: 59.38%.\n",
            "\t\tGenerator loss: 1.085394.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_14.png\n",
            "\tEpoch 7500:\n",
            "\t\tDiscriminator loss: 0.572957.\n",
            "\t\tDiscriminator accuracy: 73.44%.\n",
            "\t\tGenerator loss: 1.135040.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_15.png\n",
            "\tEpoch 8000:\n",
            "\t\tDiscriminator loss: 0.674360.\n",
            "\t\tDiscriminator accuracy: 51.56%.\n",
            "\t\tGenerator loss: 1.156536.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_16.png\n",
            "\tEpoch 8500:\n",
            "\t\tDiscriminator loss: 0.569367.\n",
            "\t\tDiscriminator accuracy: 68.75%.\n",
            "\t\tGenerator loss: 1.181620.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_17.png\n",
            "\tEpoch 9000:\n",
            "\t\tDiscriminator loss: 0.520870.\n",
            "\t\tDiscriminator accuracy: 82.81%.\n",
            "\t\tGenerator loss: 1.214165.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_18.png\n",
            "\tEpoch 9500:\n",
            "\t\tDiscriminator loss: 0.514799.\n",
            "\t\tDiscriminator accuracy: 76.56%.\n",
            "\t\tGenerator loss: 1.305778.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_19.png\n",
            "\tEpoch 9999:\n",
            "\t\tDiscriminator loss: 0.609564.\n",
            "\t\tDiscriminator accuracy: 68.75%.\n",
            "\t\tGenerator loss: 1.175492.\n",
            "\t\tCompleted in 25s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_test_19.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_0.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_1.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_2.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_3.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_4.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_5.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_6.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_7.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_8.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress/mnist_f_dress_final_9.png\n",
            "Images saved in /content/drive/My Drive/Colab Notebooks/lab4/./outputs/mnist_f_dress directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHY6xfax8Oyd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}