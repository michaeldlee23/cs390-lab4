{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpwDSGMaowvG44grXSU0u5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaeldlee23/cs390-lab4/blob/master/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F-WiwbhpcEQ",
        "outputId": "c1cf1d7c-cb9e-4d6b-e79e-8372cafcae15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuAIXJieoyVP"
      },
      "source": [
        "# CS390-NIP GAN lab\n",
        "# Max Jacobson / Sri Cherukuri / Anthony Niemiec\n",
        "# FA2020\n",
        "# uses Fashion MNIST https://www.kaggle.com/zalando-research/fashionmnist \n",
        "# uses CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import imageio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pashueYgo2jC"
      },
      "source": [
        "random.seed(1618)\n",
        "np.random.seed(1618)\n",
        "tf.compat.v1.set_random_seed(1618)\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "DRIVE_PREFIX = '/content/drive/My Drive/Colab Notebooks/lab4/'\n",
        "\n",
        "# NOTE: mnist_d is no credit\n",
        "# NOTE: cifar_10 is extra credit\n",
        "#DATASET = \"mnist_d\"\n",
        "DATASET = \"mnist_f\"\n",
        "#DATASET = \"cifar_10\"\n",
        "\n",
        "if DATASET == \"mnist_d\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    LABEL = \"numbers\"\n",
        "elif DATASET == \"mnist_f\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    CLASSLIST = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        "    # TODO: choose a label to train on from the CLASSLIST above\n",
        "    LABEL = \"sneaker\"\n",
        "elif DATASET == \"cifar_10\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (32, 32, 3)\n",
        "    CLASSLIST = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "    LABEL = \"airplane\"\n",
        "\n",
        "IMAGE_SIZE = IH*IW*IZ\n",
        "\n",
        "NOISE_SIZE = 100    # length of noise array\n",
        "\n",
        "# file prefixes and directory\n",
        "OUTPUT_NAME = DATASET + \"_\" + LABEL\n",
        "OUTPUT_DIR = DRIVE_PREFIX + \"./outputs/\" + OUTPUT_NAME\n",
        "\n",
        "# NOTE: switch to True in order to receive debug information\n",
        "VERBOSE_OUTPUT = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Knbe7rFo5kK"
      },
      "source": [
        "################################### DATA FUNCTIONS ###################################\n",
        "\n",
        "# Load in and report the shape of dataset\n",
        "def getRawData():\n",
        "    if DATASET == \"mnist_f\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    elif DATASET == \"cifar_10\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.cifar10.load_data()\n",
        "    elif DATASET == \"mnist_d\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.mnist.load_data()\n",
        "    print(\"Shape of xTrain dataset: %s.\" % str(xTrain.shape))\n",
        "    print(\"Shape of yTrain dataset: %s.\" % str(yTrain.shape))\n",
        "    print(\"Shape of xTest dataset: %s.\" % str(xTest.shape))\n",
        "    print(\"Shape of yTest dataset: %s.\" % str(yTest.shape))\n",
        "    return ((xTrain, yTrain), (xTest, yTest))\n",
        "\n",
        "# Filter out the dataset to only include images with our LABEL, meaning we may also discard\n",
        "# class labels for the images because we know exactly what to expect\n",
        "def preprocessData(raw):\n",
        "    ((xTrain, yTrain), (xTest, yTest)) = raw\n",
        "    if DATASET == \"mnist_d\":\n",
        "        xP = np.r_[xTrain, xTest]\n",
        "    else:\n",
        "        c = CLASSLIST.index(LABEL)\n",
        "        x = np.r_[xTrain, xTest]\n",
        "        y = np.r_[yTrain, yTest].flatten()\n",
        "        ilist = [i for i in range(y.shape[0]) if y[i] == c]\n",
        "        xP = x[ilist]\n",
        "    # NOTE: Normalize from 0 to 1 or -1 to 1\n",
        "    #xP = xP/255.0\n",
        "    xP = xP/127.5 - 1\n",
        "    print(\"Shape of Preprocessed dataset: %s.\" % str(xP.shape))\n",
        "    return xP"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQgvQcuo9jG"
      },
      "source": [
        "################################### CREATING A GAN ###################################\n",
        "\n",
        "# Model that discriminates between fake and real dataset images\n",
        "def buildDiscriminator(dropRate=0.25):\n",
        "    # Calculating output size for Conv2D\n",
        "    # When padding = same:\n",
        "    #   H = H1 / stride\n",
        "    # When padding = valid:\n",
        "    #   H = (H1 - HF + 1) / stride\n",
        "    # Where H = output height (resp, width), H1 = input height, HF = filter height\n",
        "    model = Sequential()\n",
        "\n",
        "    # output size will be 28 / 2 = 14\n",
        "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be 14 / 2 = 7\n",
        "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(2 * dropRate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a discriminator which takes in a (28 x 28 x 1) image - possibly from mnist_f\n",
        "    #       and possibly from the generator - and outputs a single digit REAL (1) or FAKE (0)\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = IMAGE_SHAPE)\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "# Model that generates a fake image from random noise\n",
        "def buildGenerator():\n",
        "    # from https://datascience.stackexchange.com/questions/26451/how-to-calculate-the-output-shape-of-conv2d-transpose\n",
        "    # Calculating output size for Conv2DTranspose\n",
        "    # When padding = same:\n",
        "    #   H = H1 * stride\n",
        "    # When padding = valid:\n",
        "    #   H = (H1-1) * stride + HF\n",
        "    # Where H = output height (resp, width), H1 = input height, HF = filter height\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(7 * 7 * 128, input_dim = NOISE_SIZE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "\n",
        "    # output size will be 7 * 2 = 14\n",
        "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # output size will be 14 * 2 = 28\n",
        "    model.add(Conv2DTranspose(IZ, (5, 5), strides=(2,2), padding='same', activation='tanh')) #\n",
        "    model.summary()\n",
        "    # TODO: build a generator which takes in a (NOISE_SIZE) noise array and outputs a fake\n",
        "    #       mnist_f (28 x 28 x 1) image\n",
        "    assert model.output_shape == (None, IH, IW, IZ)\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = (NOISE_SIZE,))\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "def buildGAN(images, epochs = 40000, batchSize = 32, loggingInterval = 0):\n",
        "    # Setup\n",
        "    opt = Adam(lr = 0.0002)\n",
        "    loss = \"binary_crossentropy\"\n",
        "\n",
        "    # Setup adversary\n",
        "    adversary = buildDiscriminator()\n",
        "    adversary.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "    # Setup generator and GAN\n",
        "    adversary.trainable = False                     # freeze adversary's weights when training GAN\n",
        "    generator = buildGenerator()                    # generator is trained within GAN in relation to adversary performance\n",
        "    noise = Input(shape = (NOISE_SIZE,))\n",
        "    gan = Model(noise, adversary(generator(noise))) # GAN feeds generator into adversary\n",
        "    gan.compile(loss = loss, optimizer = opt)\n",
        "\n",
        "    # Training\n",
        "    trueCol = np.ones((batchSize, 1))\n",
        "    falseCol = np.zeros((batchSize, 1))\n",
        "    start = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        # Train discriminator with a true and false batch\n",
        "        batch = images[np.random.randint(0, images.shape[0], batchSize)]\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genImages = generator.predict(noise)\n",
        "        advTrueLoss = adversary.train_on_batch(batch, trueCol)\n",
        "        advFalseLoss = adversary.train_on_batch(genImages, falseCol)\n",
        "        advLoss = np.add(advTrueLoss, advFalseLoss) * 0.5\n",
        "\n",
        "        # Train generator by training GAN while keeping adversary component constant\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genLoss = gan.train_on_batch(noise, trueCol)\n",
        "\n",
        "        # Logging\n",
        "        if loggingInterval > 0 and epoch % loggingInterval == 0:\n",
        "            end = time.time()\n",
        "            print(\"\\tEpoch %d:\" % epoch)\n",
        "            print(\"\\t\\tDiscriminator loss: %f.\" % advLoss[0])\n",
        "            print(\"\\t\\tDiscriminator accuracy: %.2f%%.\" % (100 * advLoss[1]))\n",
        "            print(\"\\t\\tGenerator loss: %f.\" % genLoss)\n",
        "            print(\"\\t\\tCompleted in %ds\" % (end - start))\n",
        "            start = time.time()\n",
        "            runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_test_%d.png\" % (epoch / loggingInterval))\n",
        "\n",
        "    return (generator, adversary, gan)\n",
        "\n",
        "# Generates an image using given generator\n",
        "def runGAN(generator, outfile):\n",
        "    noise = np.random.normal(0, 1, (1, NOISE_SIZE)) # generate a random noise array\n",
        "    img = generator.predict(noise)[0]               # run generator on noise\n",
        "    img = np.squeeze(img)                           # readjust image shape if needed\n",
        "    img = (0.5*img + 0.5)*255                       # adjust values to range from 0 to 255 as needed\n",
        "    imageio.imwrite(outfile, img.astype('uint8'))   # store resulting image\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5qhTdQLoVHq",
        "outputId": "0d628054-0391-4fb1-91fd-f1bb4c951579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "################################### RUNNING THE PIPELINE #############################\n",
        "\n",
        "def main():\n",
        "    print(\"Starting %s image generator program.\" % LABEL)\n",
        "    # Make output directory\n",
        "    if not os.path.exists(OUTPUT_DIR):\n",
        "        os.makedirs(OUTPUT_DIR)\n",
        "    # Receive all of mnist_f\n",
        "    raw = getRawData()\n",
        "    # Filter for just the class we are trying to generate\n",
        "    data = preprocessData(raw)\n",
        "    # Create and train all facets of the GAN\n",
        "    (generator, adv, gan) = buildGAN(data, epochs = 20000, loggingInterval = 1000)\n",
        "    # Utilize our spooky neural net gimmicks to create realistic counterfeit images\n",
        "    for i in range(10):\n",
        "        runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_final_%d.png\" % i)\n",
        "    print(\"Images saved in %s directory.\" % OUTPUT_DIR)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting sneaker image generator program.\n",
            "Shape of xTrain dataset: (60000, 28, 28).\n",
            "Shape of yTrain dataset: (60000,).\n",
            "Shape of xTest dataset: (10000, 28, 28).\n",
            "Shape of yTest dataset: (10000,).\n",
            "Shape of Preprocessed dataset: (7000, 28, 28).\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 6,500,097\n",
            "Trainable params: 6,500,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6272)              25088     \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 14, 14, 64)        204864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 865,281\n",
            "Trainable params: 852,609\n",
            "Non-trainable params: 12,672\n",
            "_________________________________________________________________\n",
            "\tEpoch 0:\n",
            "\t\tDiscriminator loss: 0.716684.\n",
            "\t\tDiscriminator accuracy: 14.06%.\n",
            "\t\tGenerator loss: 0.529859.\n",
            "\t\tCompleted in 1s\n",
            "\tEpoch 1000:\n",
            "\t\tDiscriminator loss: 0.433400.\n",
            "\t\tDiscriminator accuracy: 78.12%.\n",
            "\t\tGenerator loss: 1.493244.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 2000:\n",
            "\t\tDiscriminator loss: 0.756325.\n",
            "\t\tDiscriminator accuracy: 56.25%.\n",
            "\t\tGenerator loss: 1.072736.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 3000:\n",
            "\t\tDiscriminator loss: 0.546875.\n",
            "\t\tDiscriminator accuracy: 70.31%.\n",
            "\t\tGenerator loss: 1.193501.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 4000:\n",
            "\t\tDiscriminator loss: 0.669591.\n",
            "\t\tDiscriminator accuracy: 67.19%.\n",
            "\t\tGenerator loss: 1.081581.\n",
            "\t\tCompleted in 53s\n",
            "\tEpoch 5000:\n",
            "\t\tDiscriminator loss: 0.637440.\n",
            "\t\tDiscriminator accuracy: 65.62%.\n",
            "\t\tGenerator loss: 1.325275.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 6000:\n",
            "\t\tDiscriminator loss: 0.539243.\n",
            "\t\tDiscriminator accuracy: 71.88%.\n",
            "\t\tGenerator loss: 1.232596.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 7000:\n",
            "\t\tDiscriminator loss: 0.494939.\n",
            "\t\tDiscriminator accuracy: 82.81%.\n",
            "\t\tGenerator loss: 1.052443.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 8000:\n",
            "\t\tDiscriminator loss: 0.519967.\n",
            "\t\tDiscriminator accuracy: 73.44%.\n",
            "\t\tGenerator loss: 1.139063.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 9000:\n",
            "\t\tDiscriminator loss: 0.586834.\n",
            "\t\tDiscriminator accuracy: 68.75%.\n",
            "\t\tGenerator loss: 1.398708.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 10000:\n",
            "\t\tDiscriminator loss: 0.600853.\n",
            "\t\tDiscriminator accuracy: 62.50%.\n",
            "\t\tGenerator loss: 1.315500.\n",
            "\t\tCompleted in 52s\n",
            "\tEpoch 11000:\n",
            "\t\tDiscriminator loss: 0.560738.\n",
            "\t\tDiscriminator accuracy: 70.31%.\n",
            "\t\tGenerator loss: 1.189632.\n",
            "\t\tCompleted in 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHY6xfax8Oyd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}