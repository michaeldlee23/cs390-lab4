{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq3FojuMYF+UEfbhSSFMWb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaeldlee23/cs390-lab4/blob/master/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F-WiwbhpcEQ",
        "outputId": "8dd9d32b-8f6b-4f60-d15b-e9ffdc469971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuAIXJieoyVP"
      },
      "source": [
        "# CS390-NIP GAN lab\n",
        "# Max Jacobson / Sri Cherukuri / Anthony Niemiec\n",
        "# FA2020\n",
        "# uses Fashion MNIST https://www.kaggle.com/zalando-research/fashionmnist \n",
        "# uses CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import imageio\n",
        "import shutil"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pashueYgo2jC"
      },
      "source": [
        "random.seed(1618)\n",
        "np.random.seed(1618)\n",
        "tf.compat.v1.set_random_seed(1618)\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "DRIVE_PREFIX = '/content/drive/My Drive/Colab Notebooks/lab4/'\n",
        "\n",
        "# NOTE: mnist_d is no credit\n",
        "# NOTE: cifar_10 is extra credit\n",
        "# DATASET = \"mnist_d\"\n",
        "# DATASET = \"mnist_f\"\n",
        "DATASET = \"cifar_10\"\n",
        "\n",
        "if DATASET == \"mnist_d\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    LABEL = \"numbers\"\n",
        "elif DATASET == \"mnist_f\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    CLASSLIST = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        "    # TODO: choose a label to train on from the CLASSLIST above\n",
        "    LABEL = \"coat\"\n",
        "elif DATASET == \"cifar_10\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (32, 32, 3)\n",
        "    CLASSLIST = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "    LABEL = \"bird\"\n",
        "\n",
        "IMAGE_SIZE = IH*IW*IZ\n",
        "\n",
        "NOISE_SIZE = 100    # length of noise array\n",
        "\n",
        "TRAIN_RATIO = 1     # Number of generator updates per discriminator update\n",
        "\n",
        "# file prefixes and directory\n",
        "OUTPUT_NAME = DATASET + \"_\" + LABEL\n",
        "OUTPUT_DIR = DRIVE_PREFIX + \"./outputs/\" + OUTPUT_NAME\n",
        "\n",
        "# Tensorbord directories\n",
        "ADV_LOG_DIR = DRIVE_PREFIX + './logs/' + OUTPUT_NAME + '/advLoss'\n",
        "GEN_LOG_DIR = DRIVE_PREFIX + './logs/' + OUTPUT_NAME + '/genLoss'\n",
        "\n",
        "# NOTE: switch to True in order to receive debug information\n",
        "VERBOSE_OUTPUT = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVuKnuWuaKrD"
      },
      "source": [
        "################################### HELPER FUNCTIONS ###################################\n",
        "def namedLogs(model, logs):\n",
        "    result = dict()\n",
        "    for l in zip(model.metrics_names, logs):\n",
        "        result[l[0]] = l[1]\n",
        "    return result\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Knbe7rFo5kK"
      },
      "source": [
        "################################### DATA FUNCTIONS ###################################\n",
        "\n",
        "# Load in and report the shape of dataset\n",
        "def getRawData():\n",
        "    if DATASET == \"mnist_f\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    elif DATASET == \"cifar_10\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.cifar10.load_data()\n",
        "    elif DATASET == \"mnist_d\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.mnist.load_data()\n",
        "    print(\"Shape of xTrain dataset: %s.\" % str(xTrain.shape))\n",
        "    print(\"Shape of yTrain dataset: %s.\" % str(yTrain.shape))\n",
        "    print(\"Shape of xTest dataset: %s.\" % str(xTest.shape))\n",
        "    print(\"Shape of yTest dataset: %s.\" % str(yTest.shape))\n",
        "    return ((xTrain, yTrain), (xTest, yTest))\n",
        "\n",
        "# Filter out the dataset to only include images with our LABEL, meaning we may also discard\n",
        "# class labels for the images because we know exactly what to expect\n",
        "def preprocessData(raw):\n",
        "    ((xTrain, yTrain), (xTest, yTest)) = raw\n",
        "    if DATASET == \"mnist_d\":\n",
        "        xP = np.r_[xTrain, xTest]\n",
        "    else:\n",
        "        c = CLASSLIST.index(LABEL)\n",
        "        x = np.r_[xTrain, xTest]\n",
        "        y = np.r_[yTrain, yTest].flatten()\n",
        "        ilist = [i for i in range(y.shape[0]) if y[i] == c]\n",
        "        xP = x[ilist]\n",
        "    # NOTE: Normalize from 0 to 1 or -1 to 1\n",
        "    #xP = xP/255.0\n",
        "    xP = xP/127.5 - 1\n",
        "    print(\"Shape of Preprocessed dataset: %s.\" % str(xP.shape))\n",
        "    return xP"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmrX6Or_pxvf"
      },
      "source": [
        "################################# BUILDING NETWORKS ##################################\n",
        "#################################      MNIST_F      ##################################\n",
        "\n",
        "# Model that discriminates between fake and real dataset images\n",
        "def buildDiscriminator(dropRate=0.2):\n",
        "    # Calculating output size for Conv2D\n",
        "    # When padding = same:\n",
        "    #   H = H1 / stride\n",
        "    # When padding = valid:\n",
        "    #   H = (H1 - HF + 1) / stride\n",
        "    # Where H = output height (resp, width), H1 = input height, HF = filter height\n",
        "    model = Sequential(name=\"MNIST_DISCRIMINATOR\")\n",
        "\n",
        "    # output shape: (14, 14, 64)\n",
        "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    # output shape: (7, 7, 128)\n",
        "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(dropRate))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(2 * dropRate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a discriminator which takes in a (28 x 28 x 1) image - possibly from mnist_f\n",
        "    #       and possibly from the generator - and outputs a single digit REAL (1) or FAKE (0)\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = IMAGE_SHAPE)\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "# Model that generates a fake image from random noise\n",
        "def buildGenerator():\n",
        "    # from https://datascience.stackexchange.com/questions/26451/how-to-calculate-the-output-shape-of-conv2d-transpose\n",
        "    # Calculating output size for Conv2DTranspose\n",
        "    # When padding = same:\n",
        "    #   H = H1 * stride\n",
        "    # When padding = valid:\n",
        "    #   H = (H1-1) * stride + HF\n",
        "    # Where H = output height (resp, width), H1 = input height, HF = filter height\n",
        "    kernelSize = (5, 5)\n",
        "    model = Sequential(name=\"MNIST_GENERATOR\")\n",
        "\n",
        "    model.add(Dense(7 * 7 * 128, input_dim = NOISE_SIZE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "\n",
        "    # Output shape: (14, 14, 64)\n",
        "    model.add(Conv2DTranspose(64, kernelSize, strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Output shape: (28, 28, 1)\n",
        "    model.add(Conv2DTranspose(IZ, kernelSize, strides=(2, 2), padding='same', activation='tanh')) \n",
        "\n",
        "    model.summary()\n",
        "    # TODO: build a generator which takes in a (NOISE_SIZE) noise array and outputs a fake\n",
        "    #       mnist_f (28 x 28 x 1) image\n",
        "    assert model.output_shape == (None, IH, IW, IZ)\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = (NOISE_SIZE,))\n",
        "    return Model(inputTensor, model(inputTensor))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQgvQcuo9jG"
      },
      "source": [
        "################################# BUILDING NETWORKS ##################################\n",
        "#################################     CIFAR_10      ##################################\n",
        "\n",
        "# Model that discriminates between fake and real dataset images\n",
        "def buildDiscriminator(dropRate=0.2):\n",
        "    model = Sequential(name=\"CIFAR_DISCRIMINATOR\")\n",
        "    kernelSize = (3, 3)\n",
        "    alpha = 0.2\n",
        "    momentum = 0.8\n",
        "\n",
        "    # output size will be (16, 16, 64)\n",
        "    model.add(Conv2D(64, kernelSize, strides=(2, 2), padding='same', input_shape=IMAGE_SHAPE))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be (8, 8, 128)\n",
        "    model.add(Conv2D(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    # model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be (4, 4, 128)\n",
        "    model.add(Conv2D(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    # model.add(Dropout(dropRate))\n",
        "\n",
        "    # output size will be (2, 2, 256)\n",
        "    model.add(Conv2D(256, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    # model.add(Dropout(dropRate))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    # model.add(Dense(1024))\n",
        "    # model.add(LeakyReLU(alpha))\n",
        "    model.add(Dropout(2 * dropRate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    inputTensor = Input(shape = IMAGE_SHAPE)\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "# Model that generates a fake image from random noise\n",
        "def buildGenerator():\n",
        "    kernelSize = (4, 4)\n",
        "    alpha = 0.2\n",
        "    momentum = 0.8\n",
        "    model = Sequential(name=\"CIFAR_GENERATOR\")\n",
        "\n",
        "    model.add(Dense(4 * 4 * 256, input_dim = NOISE_SIZE))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum))\n",
        "    \n",
        "    # output shape: (4, 4, 256)\n",
        "    model.add(Reshape((4, 4, 256)))\n",
        "\n",
        "    # output shape: (8, 8, 128)\n",
        "    model.add(Conv2DTranspose(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "\n",
        "    # output shape: (16, 16, 128)\n",
        "    model.add(Conv2DTranspose(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "\n",
        "    # output shape: (32, 32, 128)\n",
        "    model.add(Conv2DTranspose(128, kernelSize, strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha))\n",
        "    # model.add(BatchNormalization(momentum=momentum))\n",
        "    \n",
        "    # output shape: (32, 32, 3)\n",
        "    model.add(Conv2D(IZ, kernelSize, padding='same', activation='tanh')) \n",
        "\n",
        "    model.summary()\n",
        "    assert model.output_shape == (None, IH, IW, IZ)\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = (NOISE_SIZE,))\n",
        "    return Model(inputTensor, model(inputTensor))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFt6Urs0I9T"
      },
      "source": [
        "################################### CREATING A GAN ###################################\n",
        "\n",
        "def buildGAN(images, epochs = 40000, batchSize = 32, loggingInterval = 0):\n",
        "    # Setup\n",
        "    opt = Adam(0.0002, 0.5)\n",
        "    loss = \"binary_crossentropy\"\n",
        "\n",
        "    # Setup adversary\n",
        "    adversary = buildDiscriminator()\n",
        "    adversary.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "    # Setup generator and GAN\n",
        "    adversary.trainable = False                     # freeze adversary's weights when training GAN\n",
        "    generator = buildGenerator()                    # generator is trained within GAN in relation to adversary performance\n",
        "    noise = Input(shape = (NOISE_SIZE,))\n",
        "    gan = Model(noise, adversary(generator(noise))) # GAN feeds generator into adversary\n",
        "    gan.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "    # Tensorboard logging setup\n",
        "    advTensorboard = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=ADV_LOG_DIR,\n",
        "    )\n",
        "    advTensorboard.set_model(adversary)\n",
        "\n",
        "    genTensorboard = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=GEN_LOG_DIR,\n",
        "    )\n",
        "    genTensorboard.set_model(gan)\n",
        "\n",
        "    # Training\n",
        "    trueCol = np.ones((batchSize, 1))\n",
        "    falseCol = np.zeros((batchSize, 1))\n",
        "    start = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator with a true and false batch\n",
        "        batch = images[np.random.randint(0, images.shape[0], batchSize)]\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genImages = generator.predict(noise)\n",
        "        if epoch % TRAIN_RATIO == 0:\n",
        "            advTrueLoss = adversary.train_on_batch(batch, trueCol)\n",
        "            advFalseLoss = adversary.train_on_batch(genImages, falseCol)\n",
        "            advLoss = np.add(advTrueLoss, advFalseLoss) * 0.5\n",
        "\n",
        "        # Train generator by training GAN while keeping adversary component constant\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genLoss = gan.train_on_batch(noise, trueCol)\n",
        "\n",
        "        # Logging\n",
        "        if loggingInterval > 0 and epoch % loggingInterval == 0 or epoch == epochs - 1:\n",
        "            end = time.time()\n",
        "            print(\"\\tEpoch %d:\" % epoch)\n",
        "            print(\"\\t\\tDiscriminator loss: %f.\" % advLoss[0])\n",
        "            print(\"\\t\\tDiscriminator accuracy: %.2f%%.\" % (100 * advLoss[1]))\n",
        "            print(\"\\t\\tGenerator loss: %f.\" % genLoss[0])\n",
        "            print(\"\\t\\tCompleted in %ds\" % (end - start))\n",
        "            start = time.time()\n",
        "            # Tensorboard logging\n",
        "            runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_test_%d.png\" % (epoch / loggingInterval))\n",
        "            advTensorboard.on_epoch_end(epoch, namedLogs(adversary, [advLoss[0]]))\n",
        "            genTensorboard.on_epoch_end(epoch, namedLogs(gan, [genLoss[0]]))\n",
        "    advTensorboard.on_train_end(None)\n",
        "    genTensorboard.on_train_end(None)\n",
        "    return (generator, adversary, gan)\n",
        "\n",
        "# Generates an image using given generator\n",
        "def runGAN(generator, outfile):\n",
        "    noise = np.random.normal(0, 1, (1, NOISE_SIZE)) # generate a random noise array\n",
        "    img = generator.predict(noise)[0]               # run generator on noise\n",
        "    img = np.squeeze(img)                           # readjust image shape if needed\n",
        "    img = (0.5*img + 0.5)*255                       # adjust values to range from 0 to 255 as needed\n",
        "    imageio.imwrite(outfile, img.astype('uint8'))   # store resulting image\n",
        "    print('\\t\\tSaved image to %s' % outfile)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5qhTdQLoVHq",
        "outputId": "eda08a83-ecea-44e3-b584-e73cad3535ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "################################### RUNNING THE PIPELINE #############################\n",
        "\n",
        "def main():\n",
        "    print(\"Starting %s image generator program.\" % LABEL)\n",
        "    if os.path.exists(OUTPUT_DIR):\n",
        "        print('Removing old outputs...')\n",
        "        shutil.rmtree(OUTPUT_DIR)   # remove old outputs\n",
        "    if os.path.exists(ADV_LOG_DIR):\n",
        "        print('Removing old adversary logs...')\n",
        "        shutil.rmtree(ADV_LOG_DIR)  # remove old adversary logs\n",
        "    if os.path.exists(GEN_LOG_DIR):\n",
        "        print('Removing old generator logs...')\n",
        "        shutil.rmtree(GEN_LOG_DIR)  # remove old generator logs\n",
        "    print('Making new output directory...')\n",
        "    os.makedirs(OUTPUT_DIR)         # make new output directory\n",
        "    print('Making new adversary logs directory...')\n",
        "    os.makedirs(ADV_LOG_DIR)        # make new adversary logs\n",
        "    print('Making new generator logs directory...')\n",
        "    os.makedirs(GEN_LOG_DIR)        # make new generator logs\n",
        "    # Receive all of mnist_f\n",
        "    raw = getRawData()\n",
        "    # Filter for just the class we are trying to generate\n",
        "    data = preprocessData(raw)\n",
        "    # Create and train all facets of the GAN\n",
        "    if DATASET != 'cifar_10':\n",
        "        (generator, adv, gan) = buildGAN(data, epochs = 10000, loggingInterval = 500)\n",
        "    else:\n",
        "        (generator, adv, gan) = buildGAN(data, epochs = 50000,\n",
        "                                         batchSize = 128,\n",
        "                                         loggingInterval = 5000)\n",
        "    # Utilize our spooky neural net gimmicks to create realistic counterfeit images\n",
        "    for i in range(10):\n",
        "        runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_final_%d.png\" % i)\n",
        "    print(\"Images saved in %s directory.\" % OUTPUT_DIR)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting bird image generator program.\n",
            "Making new output directory...\n",
            "Making new adversary logs directory...\n",
            "Making new generator logs directory...\n",
            "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
            "Shape of yTrain dataset: (50000, 1).\n",
            "Shape of xTest dataset: (10000, 32, 32, 3).\n",
            "Shape of yTest dataset: (10000, 1).\n",
            "Shape of Preprocessed dataset: (6000, 32, 32, 3).\n",
            "Model: \"CIFAR_DISCRIMINATOR\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 519,425\n",
            "Trainable params: 519,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"CIFAR_GENERATOR\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 4096)              413696    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTr (None, 8, 8, 128)         524416    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTr (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTr (None, 32, 32, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 3)         6147      \n",
            "=================================================================\n",
            "Total params: 1,468,803\n",
            "Trainable params: 1,468,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\tEpoch 0:\n",
            "\t\tDiscriminator loss: 0.691830.\n",
            "\t\tDiscriminator accuracy: 33.20%.\n",
            "\t\tGenerator loss: 0.691307.\n",
            "\t\tCompleted in 1s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_0.png\n",
            "\tEpoch 5000:\n",
            "\t\tDiscriminator loss: 0.635107.\n",
            "\t\tDiscriminator accuracy: 67.58%.\n",
            "\t\tGenerator loss: 0.861212.\n",
            "\t\tCompleted in 621s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_1.png\n",
            "\tEpoch 10000:\n",
            "\t\tDiscriminator loss: 0.579925.\n",
            "\t\tDiscriminator accuracy: 69.92%.\n",
            "\t\tGenerator loss: 1.057337.\n",
            "\t\tCompleted in 623s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_2.png\n",
            "\tEpoch 15000:\n",
            "\t\tDiscriminator loss: 0.482058.\n",
            "\t\tDiscriminator accuracy: 75.39%.\n",
            "\t\tGenerator loss: 1.476329.\n",
            "\t\tCompleted in 619s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_3.png\n",
            "\tEpoch 20000:\n",
            "\t\tDiscriminator loss: 0.308581.\n",
            "\t\tDiscriminator accuracy: 88.28%.\n",
            "\t\tGenerator loss: 2.555242.\n",
            "\t\tCompleted in 620s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_4.png\n",
            "\tEpoch 25000:\n",
            "\t\tDiscriminator loss: 0.174438.\n",
            "\t\tDiscriminator accuracy: 93.75%.\n",
            "\t\tGenerator loss: 3.615878.\n",
            "\t\tCompleted in 622s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_5.png\n",
            "\tEpoch 30000:\n",
            "\t\tDiscriminator loss: 0.167393.\n",
            "\t\tDiscriminator accuracy: 93.75%.\n",
            "\t\tGenerator loss: 4.318857.\n",
            "\t\tCompleted in 621s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_6.png\n",
            "\tEpoch 35000:\n",
            "\t\tDiscriminator loss: 0.075395.\n",
            "\t\tDiscriminator accuracy: 96.88%.\n",
            "\t\tGenerator loss: 5.406686.\n",
            "\t\tCompleted in 619s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_7.png\n",
            "\tEpoch 40000:\n",
            "\t\tDiscriminator loss: 0.095408.\n",
            "\t\tDiscriminator accuracy: 96.48%.\n",
            "\t\tGenerator loss: 5.895609.\n",
            "\t\tCompleted in 622s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_8.png\n",
            "\tEpoch 45000:\n",
            "\t\tDiscriminator loss: 0.058737.\n",
            "\t\tDiscriminator accuracy: 98.83%.\n",
            "\t\tGenerator loss: 5.746094.\n",
            "\t\tCompleted in 621s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_9.png\n",
            "\tEpoch 49999:\n",
            "\t\tDiscriminator loss: 0.141747.\n",
            "\t\tDiscriminator accuracy: 95.70%.\n",
            "\t\tGenerator loss: 6.904260.\n",
            "\t\tCompleted in 621s\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_test_9.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_0.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_1.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_2.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_3.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_4.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_5.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_6.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_7.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_8.png\n",
            "\t\tSaved image to /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird/cifar_10_bird_final_9.png\n",
            "Images saved in /content/drive/My Drive/Colab Notebooks/lab4/./outputs/cifar_10_bird directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHY6xfax8Oyd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}